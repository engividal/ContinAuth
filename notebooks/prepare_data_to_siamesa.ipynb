{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "# `DatasetLoader` is a custom helper class to retrieve data from hdf5 file\n",
    "module_path = os.path.abspath(os.path.join(\"..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from src.utility.dataset_loader_hdf5 import DatasetLoader\n",
    "\n",
    "# Global utitlity functions are loaded from separate notebook:\n",
    "%run utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "TABLE_NAME = \"sensors_100hz\"  # Table with raw sensor data\n",
    "HMOG_HDF5 = Path.cwd().parent / \"data\" / \"processed\" / \"hmog_dataset.hdf5\"\n",
    "SEED = 712\n",
    "\n",
    "FEATURE_COLS = [\n",
    "    \"acc_x\",\n",
    "    \"acc_y\",\n",
    "    \"acc_z\",\n",
    "]\n",
    "\n",
    "REPORT_PATH = Path.cwd().parent / \"reports\" / \"figures\"  # Figures for thesis\n",
    "REPORT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# For plots and CSVs\n",
    "OUTPUT_PATH = Path.cwd() / \"output\" / \"siamesa_lstm_ocsvm\"  # Cached data & csvs\n",
    "OUTPUT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "REPORT_PATH = Path.cwd().parent / \"reports\" / \"figures\" # Figures for thesis\n",
    "REPORT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "step_width = 50\n",
    "window_size = 100\n",
    "max_pairs_per_session = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "hmog = DatasetLoader(\n",
    "    hdf5_file=HMOG_HDF5,\n",
    "    table_name=TABLE_NAME,\n",
    "    max_subjects=None,\n",
    "    task_types=[],\n",
    "    exclude_subjects=[],   \n",
    "    exclude_cols=[],\n",
    "    seed=SEED,\n",
    ")\n",
    "hmog.data_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize Features\n",
    "\n",
    "print(\"Normalize all data before splitting into train and test sets...\")\n",
    "hmog.all, scalers = utils_custom_scale(\n",
    "    hmog.all,\n",
    "    scale_cols=FEATURE_COLS,        \n",
    "    feature_cols=FEATURE_COLS,\n",
    "    scaler_name=\"robust\",\n",
    "    scope=\"subject\",\n",
    "    plot=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "\n",
    "hmog.split_train_valid_train_test(\n",
    "    n_valid_train=20,\n",
    "    n_valid_test=5,\n",
    "    n_test_train=20,\n",
    "    n_test_test=5,\n",
    ")\n",
    "hmog.data_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check splits\n",
    "\n",
    "#utils_split_report(hmog.valid_train)\n",
    "#utils_split_report(hmog.valid_test)\n",
    "#utils_split_report(hmog.test_train)\n",
    "utils_split_report(hmog.test_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape & cache Set for Training Siamese Network:\n",
    "\n",
    "df_siamese_train = utils_reshape_features(\n",
    "    hmog.valid_train,\n",
    "    feature_cols=FEATURE_COLS,\n",
    "    window_size=window_size,\n",
    "    step_width=step_width,\n",
    ")\n",
    "\n",
    "# Clean memory\n",
    "del hmog.train\n",
    "%reset_selective -f hmog.train\n",
    "\n",
    "print(\"Validation data after reshaping:\")\n",
    "display(df_siamese_train.head())\n",
    "\n",
    "# Store iterim data\n",
    "df_siamese_train.to_msgpack(OUTPUT_PATH / \"df_siamese_train.msg\")\n",
    "\n",
    "# Clean memory\n",
    "%reset_selective -f df_siamese_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape & cache Set for Validating Siamese Network: (also used to optimize OCSVM)\n",
    "\n",
    "df_siamese_valid = utils_reshape_features(\n",
    "    hmog.valid_test,\n",
    "    feature_cols=FEATURE_COLS,\n",
    "    window_size=window_size,\n",
    "    step_width=step_width,\n",
    ")\n",
    "\n",
    "del hmog.valid\n",
    "%reset_selective -f hmog.valid\n",
    "\n",
    "print(\"Testing data after reshaping:\")\n",
    "display(df_siamese_valid.head())\n",
    "\n",
    "# Store iterim data\n",
    "df_siamese_valid.to_msgpack(OUTPUT_PATH / \"df_siamese_valid.msg\")\n",
    "\n",
    "# Clean memory\n",
    "%reset_selective -f df_siamese_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape & cache Set for Training/Validation OCSVM:\n",
    "\n",
    "df_ocsvm_train_valid = utils_reshape_features(\n",
    "    hmog.test_train,\n",
    "    feature_cols=FEATURE_COLS,\n",
    "    window_size=window_size,\n",
    "    step_width=step_width,\n",
    ")\n",
    "\n",
    "del hmog.test_train\n",
    "%reset_selective -f hmog.test_train\n",
    "\n",
    "print(\"Testing data after reshaping:\")\n",
    "display(df_ocsvm_train_valid.head())\n",
    "\n",
    "# Store iterim data\n",
    "df_ocsvm_train_valid.to_msgpack(OUTPUT_PATH / \"df_ocsvm_train_valid.msg\")\n",
    "\n",
    "# Clean memory\n",
    "%reset_selective -f df_ocsvm_train_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape & cache Set for Training/Testing OCSVM:\n",
    "\n",
    "df_ocsvm_train_test = utils_reshape_features(\n",
    "    hmog.test_test,\n",
    "    feature_cols=FEATURE_COLS,\n",
    "    window_size=window_size,\n",
    "    step_width=step_width,\n",
    ")\n",
    "\n",
    "del hmog.test_test\n",
    "%reset_selective -f hmog.test_test\n",
    "\n",
    "print(\"Testing data after reshaping:\")\n",
    "display(df_ocsvm_train_test.head())\n",
    "\n",
    "# Store iterim data\n",
    "df_ocsvm_train_test.to_msgpack(OUTPUT_PATH / \"df_ocsvm_train_test.msg\")\n",
    "\n",
    "# Clean memory\n",
    "%reset_selective -f df_ocsvm_train_test\n",
    "%reset_selective -f df_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Siamesa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "\n",
    "df_siamese_train = pd.read_msgpack(OUTPUT_PATH / \"df_siamese_train.msg\")\n",
    "df_siamese_valid = pd.read_msgpack(OUTPUT_PATH / \"df_siamese_valid.msg\")\n",
    "\n",
    "type(df_siamese_valid)\n",
    "pd.unique(df_siamese_train[\"task_type\"])\n",
    "#df_siamese_valid[\"task_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainning Pairs\n",
    "\n",
    "def build_pairs(df):\n",
    "    # Limit samples per subject to sample of shortest session\n",
    "    df = df.groupby(\"session\", group_keys=False).apply(\n",
    "        lambda x: x.sample(min(len(x), max_pairs_per_session), random_state=SEED)\n",
    "    )\n",
    "    df_pairs = None\n",
    "\n",
    "    # Split samples subject wise 50:50\n",
    "    # ---------------\n",
    "    df_positives = None\n",
    "    df_negatives = None\n",
    "\n",
    "    for subject in df[\"subject\"].unique():\n",
    "        # Shuffle\n",
    "        df_subj = df[df[\"subject\"] == subject].sample(frac=1, random_state=SEED)\n",
    "\n",
    "        # Make rows even\n",
    "        if len(df_subj) % 2 != 0:\n",
    "            df_subj = df_subj.iloc[:-1]\n",
    "\n",
    "        half = len(df_subj) // 2\n",
    "\n",
    "        df_positives = pd.concat([df_positives, df_subj.iloc[:half]])\n",
    "        df_negatives = pd.concat([df_negatives, df_subj.iloc[half:]])\n",
    "\n",
    "    # Positive Pairs\n",
    "    # ---------------\n",
    "    df_positive_left = None\n",
    "    df_positive_right = None\n",
    "\n",
    "    for subject in df_positives[\"subject\"].unique():\n",
    "        df_subj = df[df[\"subject\"] == subject]\n",
    "        # Make rows even\n",
    "        if len(df_subj) % 2 != 0:\n",
    "            df_subj = df_subj.iloc[:-1]\n",
    "\n",
    "        # Split in half\n",
    "        half = len(df_subj) // 2\n",
    "        df_positive_left = pd.concat([df_positive_left, df_subj.iloc[:half]])\n",
    "        df_positive_right = pd.concat([df_positive_right, df_subj.iloc[half:]])\n",
    "\n",
    "    df_positive_left = df_positive_left.reset_index(drop=True)\n",
    "    df_positive_right = df_positive_right.reset_index(drop=True)\n",
    "    df_positive_left.columns = [\"left_\" + c for c in df_positive_left.columns]\n",
    "    df_positive_right.columns = [\"right_\" + c for c in df_positive_right.columns]\n",
    "\n",
    "    df_positives = pd.concat(\n",
    "        [df_positive_left, df_positive_right],\n",
    "        axis=1,\n",
    "        sort=False,\n",
    "        join_axes=[df_positive_left.index],\n",
    "    )\n",
    "\n",
    "    # Negative Pairs\n",
    "    # ---------------\n",
    "    # Make rows even\n",
    "    if len(df_negatives) % 2 != 0:\n",
    "        df_negatives = df_negatives.iloc[:-1]\n",
    "\n",
    "    # Split in half\n",
    "    half = len(df_negatives) // 2\n",
    "    df_negative_left = df_negatives.iloc[half:].reset_index(drop=True)\n",
    "    df_negative_right = df_negatives.iloc[:half].reset_index(drop=True)\n",
    "\n",
    "    # Name columns\n",
    "    df_negative_left.columns = [\"left_\" + c for c in df_negative_left.columns]\n",
    "    df_negative_right.columns = [\"right_\" + c for c in df_negative_right.columns]\n",
    "\n",
    "    # Combine\n",
    "    df_negatives = pd.concat(\n",
    "        [df_negative_left, df_negative_right],\n",
    "        axis=1,\n",
    "        sort=False,\n",
    "        join_axes=[df_negative_left.index],\n",
    "    )\n",
    "\n",
    "    # Combine both Pairs\n",
    "    # ---------------\n",
    "    # Balance pairs\n",
    "    min_len = min(len(df_positives), len(df_negatives))\n",
    "    df_positives = df_positives.sample(n=min_len, random_state=SEED)\n",
    "    df_negatives = df_negatives.sample(n=min_len, random_state=SEED)\n",
    "\n",
    "    # Combine\n",
    "    df_pairs = pd.concat([df_positives, df_negatives], sort=False)\n",
    "\n",
    "    # Shuffle\n",
    "    df_pairs = df_pairs.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "\n",
    "    # Set Label\n",
    "    df_pairs[\"label\"] = np.where(\n",
    "        df_pairs[\"left_subject\"] == df_pairs[\"right_subject\"], 1, 0\n",
    "    )\n",
    "\n",
    "    return df_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seconds_per_subject = 60\n",
    "frequency = 100\n",
    "samples_per_subject_train = math.ceil(\n",
    "            (seconds_per_subject * 100)\n",
    "            / (100 / frequency)\n",
    "            / window_size\n",
    "        )\n",
    "\n",
    "samples_per_subject_test = math.ceil(\n",
    "            (seconds_per_subject * 100)\n",
    "            / (100 / frequency)\n",
    "            / window_size\n",
    "        )\n",
    "samples_per_subject_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce observations/samples per\n",
    "print(\"Sample per session before reduction:\\n \")\n",
    "display(df_siamese_train[\"session\"].value_counts().head(3))\n",
    "display(df_siamese_valid[\"session\"].value_counts().head(3))\n",
    "\n",
    "df_siamese_train = df_siamese_train.groupby(\"session\", group_keys=False).apply(\n",
    "    lambda x: x.sample(n=min(len(x), samples_per_subject_train), random_state=SEED)\n",
    ")\n",
    "\n",
    "df_siamese_valid = df_siamese_valid.groupby(\"session\", group_keys=False).apply(\n",
    "    lambda x: x.sample(n=min(len(x), samples_per_subject_test), random_state=SEED)\n",
    ")\n",
    "\n",
    "print(\"\\n\\nSample per session after reduction:\\n\")\n",
    "display(df_siamese_train[\"session\"].value_counts().head(3))\n",
    "display(df_siamese_valid[\"session\"].value_counts().head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_siamese_train_pairs = build_pairs(df_siamese_train)\n",
    "df_siamese_valid_pairs = build_pairs(df_siamese_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DataFrame Info:\")\n",
    "display(df_siamese_train_pairs.info())\n",
    "\n",
    "print(\"\\n\\nHead:\")\n",
    "display(df_siamese_train_pairs.head(5))\n",
    "\n",
    "print(\"\\n\\nAny NaN values?\")\n",
    "display(df_siamese_train_pairs.isnull().sum(axis = 0))\n",
    "\n",
    "df_left_sub = df_siamese_train_pairs.groupby(\"left_subject\")[\"left_subject\"].count()\n",
    "df_right_sub = df_siamese_train_pairs.groupby(\"right_subject\")[\"right_subject\"].count()\n",
    "df_temp = pd.concat([df_left_sub, df_right_sub])\n",
    "\n",
    "print(\"\\n\\n\\nDistribution of Samples per Subjects in training Data\")\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    ncols=2, nrows=1, figsize=(5.473, 2), dpi=180, gridspec_kw={\"width_ratios\": [1, 5]}\n",
    ")\n",
    "df_siamese_train_pairs[\"label\"].value_counts().rename(\n",
    "    index={0: \"Negative\\nPairs\", 1: \"Positive\\nPairs\"}\n",
    ").plot.bar(ax=axes[0], rot=0, color=MAGENTA)\n",
    "axes[0].tick_params(axis=\"x\", which=\"major\", pad=7)\n",
    "df_temp.groupby(df_temp.index).sum().plot.bar(ax=axes[1], width=0.6)\n",
    "fig.tight_layout()\n",
    "\n",
    "utils_save_plot(plt, REPORT_PATH / f\"reproduced-siamese-lstm-ocsvm-pair-dist.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Cache Pairs  \n",
    "df_siamese_train_pairs.to_msgpack(OUTPUT_PATH / \"df_siamese_train_pairs.msg\")\n",
    "df_siamese_valid_pairs.to_msgpack(OUTPUT_PATH / \"df_siamese_valid_pairs.msg\")\n",
    "\n",
    "# Clean Memory\n",
    "%reset_selective -f df_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
