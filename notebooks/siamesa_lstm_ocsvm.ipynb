{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-residence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data loaded from another notebook\n",
    "%run prepare_data_to_siamesa.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sorted-injury",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Cache Pairs\n",
    "df_siamese_train_pairs = pd.read_msgpack(OUTPUT_PATH / \"df_siamese_train_pairs.msg\")\n",
    "df_siamese_valid_pairs = pd.read_msgpack(OUTPUT_PATH / \"df_siamese_valid_pairs.msg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moving-solomon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Def Functions\n",
    "def k_euclidean_dist(t):\n",
    "    x = t[0]\n",
    "    y = t[1]    \n",
    "    return K.sqrt(K.sum(K.square(x - y), axis=-1, keepdims=True))\n",
    "\n",
    "def k_contrastive_loss(y_true, dist):\n",
    "    \"\"\"Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    \"\"\"\n",
    "    margin = P.margin\n",
    "    return K.mean(y_true * K.square(dist) + (1 - y_true) * K.square(K.maximum(margin - dist, 0)))\n",
    "\n",
    "def contrastive_loss_test(y_true, dist):\n",
    "    \"\"\"Test function above using implementation with numpy instead tensors.\"\"\"\n",
    "    margin = P.margin\n",
    "    return y_true * np.square(dist) + (1 - y_true) * np.square(np.max(margin - dist, 0))\n",
    "\n",
    "# Siamese Model with 2D Filters, as derived from Centeno et al. (2018)\n",
    "def build_model_2d(input_shape, filters):\n",
    "    \"\"\"\n",
    "        Siamese CNN architecture with 3D input and 2D filters\n",
    "    \"\"\"\n",
    "    # Define the tensors for the two input images\n",
    "    left_inputs = Input(input_shape, name=\"left_inputs\")\n",
    "    right_inputs = Input(input_shape, name=\"right_inputs\")\n",
    "\n",
    "    # Convolutional Neural Network\n",
    "    inputs = Input(input_shape, name=\"input\")\n",
    "    x = Conv2D(filters[0], (7, 7), padding=\"same\", activation=\"tanh\", name=\"conv1\")(inputs)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), padding=\"same\", name=\"mp1\")(x)\n",
    "    x = Conv2D(filters[1], (5, 5), padding=\"same\", activation=\"tanh\", name=\"conv2\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), padding=\"same\", name=\"mp2\")(x)\n",
    "    x = Conv2D(filters[2], (3, 3), padding=\"same\", activation=\"tanh\", name=\"conv3\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), padding=\"same\", name=\"mp3\")(x)\n",
    "    x = Conv2D(filters[3], (3, 3), padding=\"same\", activation=\"tanh\", name=\"conv4\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), padding=\"same\", name=\"mp4\")(x)\n",
    "    x = Flatten(name=\"flat\")(x)\n",
    "    \n",
    "    # Basemodel instance\n",
    "    basemodel = Model(inputs, x, name=\"basemodel\")\n",
    "\n",
    "    # using same instance of \"basemodel\" to share weights between left/right networks\n",
    "    encoded_l = basemodel(left_inputs)\n",
    "    encoded_r = basemodel(right_inputs)\n",
    "\n",
    "    # Add a customized layer to compute the distance between the encodings\n",
    "    distance_layer = Lambda(k_euclidean_dist, name=\"distance\")([encoded_l, encoded_r])\n",
    "\n",
    "    # Combine into one net\n",
    "    siamese_net = Model(inputs=[left_inputs, right_inputs], outputs=distance_layer)\n",
    "\n",
    "    # return the model\n",
    "    return siamese_net, basemodel\n",
    "\n",
    "# Siamese Model with 1D Filters, similar than Centeno et al. (2018)\n",
    "def build_model_1d(input_shape, filters):\n",
    "    \"\"\"\n",
    "        Model architecture\n",
    "    \"\"\"\n",
    "    # Define the tensors for the two input images\n",
    "    left_inputs = Input(input_shape, name=\"left_inputs\")\n",
    "    right_inputs = Input(input_shape, name=\"right_inputs\")\n",
    "\n",
    "    # Convolutional Neural Network\n",
    "    inputs = Input(input_shape, name=\"input\")\n",
    "    x = Conv1D(filters[0], 7, activation=\"elu\", padding=\"same\", name=\"conv1\")(inputs)\n",
    "    x = MaxPooling1D(pool_size=2, name=\"mp1\")(x)\n",
    "    x = Conv1D(filters[1], 5, activation=\"elu\", padding=\"same\", name=\"conv2\")(x)\n",
    "    x = MaxPooling1D(pool_size=2, name=\"mp2\")(x)\n",
    "    x = Conv1D(filters[2], 3, activation=\"elu\", padding=\"same\", name=\"conv3\")(x)\n",
    "    x = MaxPooling1D(pool_size=2, name=\"mp3\")(x)\n",
    "    x = Conv1D(filters[3], 3, activation=\"elu\", padding=\"same\", name=\"conv4\")(x)\n",
    "    x = MaxPooling1D(pool_size=2, name=\"mp5\")(x)\n",
    "    x = Flatten(name=\"flat\")(x)\n",
    "\n",
    "    # Generate the encodings (feature vectors) for the two images\n",
    "    basemodel = Model(inputs, x, name=\"basemodel\")\n",
    "\n",
    "    # using same instance of \"basemodel\" to share weights between left/right networks\n",
    "    encoded_l = basemodel(left_inputs)\n",
    "    encoded_r = basemodel(right_inputs)\n",
    "\n",
    "    # Add a customized layer to compute the absolute difference between the encodings\n",
    "    distance_layer = Lambda(k_euclidean_dist, name=\"distance\")([encoded_l, encoded_r])\n",
    "\n",
    "    siamese_net = Model(inputs=[left_inputs, right_inputs], outputs=distance_layer)\n",
    "\n",
    "    # return the model\n",
    "    return siamese_net, basemodel\n",
    "\n",
    "# Siamese Model with FCN architecture\n",
    "def build_model_fcn(input_shape, filters):\n",
    "    # Define the tensors for the two input images\n",
    "    left_inputs = Input(input_shape, name=\"left_inputs\")\n",
    "    right_inputs = Input(input_shape, name=\"right_inputs\")\n",
    "\n",
    "    # Convolutional Neural Network\n",
    "    inputs = Input(input_shape, name=\"input\")\n",
    "    x = Conv1D(\n",
    "        filters=filters[0],\n",
    "        kernel_size=8,\n",
    "        strides=1,\n",
    "        activation=None,\n",
    "        padding=\"same\",\n",
    "        name=\"conv1\",\n",
    "    )(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(0.1, name=\"drop1\")(x)\n",
    "    x = Conv1D(\n",
    "        filters=filters[1],\n",
    "        kernel_size=5,\n",
    "        strides=1,\n",
    "        activation=None,\n",
    "        padding=\"same\",\n",
    "        name=\"conv2\",\n",
    "    )(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(0.1, name=\"drop2\")(x)\n",
    "    x = Conv1D(\n",
    "        filters=filters[2],\n",
    "        kernel_size=3,\n",
    "        strides=1,\n",
    "        activation=None,\n",
    "        padding=\"same\",\n",
    "        name=\"conv3\",\n",
    "    )(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dense(32, activation=\"sigmoid\", name=\"dense\")(x) # <--- !!!!!!!!!!!!\n",
    "\n",
    "    # Basemodel instance\n",
    "    basemodel = Model(inputs, x, name=\"basemodel\")\n",
    "\n",
    "    # using same instance of \"basemodel\" to share weights between left/right networks\n",
    "    encoded_l = basemodel(left_inputs)\n",
    "    encoded_r = basemodel(right_inputs)\n",
    "\n",
    "    # Add a customized layer to compute the distance between the encodings\n",
    "    distance_layer = Lambda(k_euclidean_dist, name=\"distance\")([encoded_l, encoded_r])\n",
    "\n",
    "    # Combine into one net\n",
    "    siamese_net = Model(inputs=[left_inputs, right_inputs], outputs=distance_layer)\n",
    "\n",
    "    # return the model\n",
    "    return siamese_net, basemodel\n",
    "\n",
    "def get_model(name, window_size, feature_cols, filters):\n",
    "    print(f\"Using Model variant {name}...\")\n",
    "    if name == \"1d\":\n",
    "        model, basemodel = build_model_1d((window_size, len(feature_cols)), filters)\n",
    "    elif name == \"2d\":\n",
    "        model, basemodel = build_model_2d((window_size, len(feature_cols), 1), filters)\n",
    "    elif name == \"fcn\":\n",
    "        model, basemodel = build_model_fcn((window_size, len(feature_cols)), filters)\n",
    "    else:\n",
    "        raise BaseException(\"Error: Not a valid model name: {1d, 2d, fcn}\")\n",
    "\n",
    "    return model, basemodel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-manor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect model architecture:\n",
    "temp_model, temp_basemodel = get_model(P.model_variant, P.window_size, P.feature_cols, P.filters)\n",
    "\n",
    "temp_basemodel.summary()\n",
    "temp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romance-sound",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training SiamesaLSTM with 60 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diagnostic-stock",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-driver",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a Individual Model for each user (30 users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matched-script",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running for Authentication Reability(ocsvm) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
